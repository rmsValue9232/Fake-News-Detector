{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875    It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news.csv\",index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8476     FAKE\n",
       "10294    FAKE\n",
       "3608     REAL\n",
       "10142    FAKE\n",
       "875      REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.label\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(df[\"text\"],labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `TfidfVectorizer`\n",
    "\n",
    "`TfidfVectorizer` is a **Bag of n-grams** representation transformer that treats a body of text, here the text of a news article, into a feature vector representation that ignores their relative position and treats it as a bag of words.\n",
    "It is equivalent to `CountVectorizer` followed by `TfidfTransformer`.\n",
    "\n",
    "1. `CountVectorizer` achieves the following:\n",
    "    - **Tokenization**: Extracts words from sentences as tokens (by treating spaces and punctuations as token separators) and gives them integer IDs.\n",
    "    - **Counting**: Counts the occurence of tokens in each document/text file.\n",
    "    - Returns a sparse matrix where each row corresponds to a text file, and each column index refers to the token IDs.\n",
    "2. `TfidfTransformer` achieves the following:\n",
    "    - The words/tokens with a high occurence frequency *across all the documents* (like \"a\", \"is\", \"the\", ...) provide little to no information, and hence need to weighed down to less significance than other tokens.\n",
    "    - Achieves this using a factor weight **inverse document frequency** (for each term, calculated over all documents) multiplied to the **term-frequency** (for each term in each document):\n",
    "    - $$ \\text{idf(term)} = \\text{log}\\frac{1+n}{1+\\text{df(term)}} + 1 $$\n",
    "    - Adjusted count becomes: $$\\text{tf-idf(term, doc) = tf(term, doc)} \\times \\text{idf(term)}$$\n",
    "    - Each feature column vector is then normalized.\n",
    "\n",
    "> `stop_words` are the set of words (like \"and\", \"the\", \"him\", ...) that the vectorizer needs to ignore, as they are not relevant/informative to the content of the text itself.\n",
    "\n",
    "> `max_df` ensures here that words with document frequency well over its value are ignored/not considered in the vectorization process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068, 61651)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56381)\t0.03622223988286098\n",
      "  (0, 16314)\t0.053492157980948106\n",
      "  (0, 19620)\t0.030351855107005405\n",
      "  (0, 52607)\t0.04266045446208797\n",
      "  (0, 14900)\t0.039165339742818085\n",
      "  (0, 53749)\t0.029756205182552464\n",
      "  (0, 15211)\t0.07772572986248194\n",
      "  (0, 61154)\t0.06726619958695557\n",
      "  (0, 59042)\t0.047893261248723944\n",
      "  (0, 42972)\t0.03152542343098286\n",
      "  (0, 54232)\t0.038673616329284524\n",
      "  (0, 59249)\t0.04106143649018827\n",
      "  (0, 28891)\t0.06514397995138038\n",
      "  (0, 41708)\t0.03983513460128018\n",
      "  (0, 50192)\t0.045331181477256094\n",
      "  (0, 44691)\t0.0318676439567658\n",
      "  (0, 11820)\t0.046381950858248124\n",
      "  (0, 7682)\t0.04137048243377956\n",
      "  (0, 50343)\t0.10196965191544219\n",
      "  (0, 48095)\t0.021092647294770877\n",
      "  (0, 17916)\t0.03674587236023286\n",
      "  (0, 46027)\t0.10236534701241509\n",
      "  (0, 16993)\t0.02775494464904786\n",
      "  (0, 55006)\t0.03368300200002207\n",
      "  (0, 51389)\t0.03397042876291898\n",
      "  :\t:\n",
      "  (5067, 32909)\t0.09429823872256275\n",
      "  (5067, 59221)\t0.11305513144362901\n",
      "  (5067, 14649)\t0.03772971846597005\n",
      "  (5067, 55827)\t0.2218263076177088\n",
      "  (5067, 10398)\t0.029198031075976353\n",
      "  (5067, 46158)\t0.037013973826002855\n",
      "  (5067, 60684)\t0.022935168393493133\n",
      "  (5067, 53139)\t0.025628375412833703\n",
      "  (5067, 14556)\t0.04989667741743244\n",
      "  (5067, 59249)\t0.09370008504693801\n",
      "  (5067, 48095)\t0.09626467139586602\n",
      "  (5067, 54706)\t0.02438296419332449\n",
      "  (5067, 54235)\t0.18013712617861882\n",
      "  (5067, 23649)\t0.11715980750719378\n",
      "  (5067, 60291)\t0.02511088091736429\n",
      "  (5067, 30025)\t0.07803429885512414\n",
      "  (5067, 4919)\t0.039597295646358985\n",
      "  (5067, 24041)\t0.031458613144788115\n",
      "  (5067, 51148)\t0.03759621365205542\n",
      "  (5067, 47648)\t0.051281746021764794\n",
      "  (5067, 40793)\t0.12848334208123888\n",
      "  (5067, 57811)\t0.028627812267104712\n",
      "  (5067, 51968)\t0.04662099560930727\n",
      "  (5067, 57236)\t0.05398142449766798\n",
      "  (5067, 24260)\t0.029565269989545447\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `PassiveAggressiveClassifier`\n",
    "\n",
    "Passive Aggressive Classifier is a subset of online learning linear classifier alogrithms that are appropriate for large scale learning as they learn each sample (here article text body) by sample, they only learn/ update the weights when a new sample does not get classified correctly with weights built from previous iterations, which is termed as becoming aggressive only when it does mis-classification, otherwise it is passive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 92.9%\n"
     ]
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=100)\n",
    "pac.fit(tfidf_train, y_train)\n",
    "\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy is {round(score*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[589,  49],\n",
       "       [ 41, 588]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat = confusion_matrix(y_test, y_pred, labels=['FAKE', 'REAL'])\n",
    "cmat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
